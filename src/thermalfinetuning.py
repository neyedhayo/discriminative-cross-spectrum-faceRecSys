# -*- coding: utf-8 -*-
"""ThermalFIneTuning.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1MzB5ztOvbAaYoIAQ4b6-kgi-EJ3K60x1
"""

from google.colab import drive
drive.mount('/content/drive/')

import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array
from tensorflow.keras.applications import VGG16
from tensorflow.keras import models, layers, optimizers
from keras.models import Model
from keras import layers
from keras import models
from keras.layers import BatchNormalization
from tensorflow.keras.utils import Sequence

import os, shutil
import numpy as np
import time
import io
from PIL import Image


from keras import metrics
import functools
from functools import partial

import matplotlib.pyplot as plt

# Load the VGG16 model
conv_base = VGG16(weights='imagenet', include_top=False, input_shape=(72, 96, 3))

conv_base.summary()

for i in range (1,10):
    conv_base.layers.pop()

conv_base.summary()

inp = conv_base.input
out =conv_base.layers[-1].output

thermalModel = Model(inp, out)

#From the first 10 layers, only the last three are set up to allow the training.
cont = 0
for layer in thermalModel.layers:
    cont = cont + 1
    if (cont >= 8):
        layer.trainable = True
    else:
        layer.trainable = False

thermalModel.summary()

def count_directories(path):
    return len([name for name in os.listdir(path) if os.path.isdir(os.path.join(path, name))])

train_classes = count_directories('/content/drive/MyDrive/ExtractedTerravicDatabase_subset/train')
test_classes = count_directories('/content/drive/MyDrive/ExtractedTerravicDatabase_subset/test')
validation_classes = count_directories('/content/drive/MyDrive/ExtractedTerravicDatabase_subset/val')

print(f"Training classes: {train_classes}")
print(f"Testing classes: {test_classes}")
print(f"Validation classes: {validation_classes}")

# Directories for train, val, test
train_dir = '/content/drive/MyDrive/ExtractedTerravicDatabase_subset/train'
val_dir = '/content/drive/MyDrive/ExtractedTerravicDatabase_subset/val'
test_dir = '/content/drive/MyDrive/ExtractedTerravicDatabase_subset/test'

model = models.Sequential()
model.add(thermalModel)
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.BatchNormalization())
model.add(layers.Flatten())
# model.add(layers.Dense(256, activation='relu'))
# model.add(layers.Dropout(0.5))
model.add(layers.Dense(16, activation='softmax'))

model.summary()

top2_acc = functools.partial(metrics.top_k_categorical_accuracy, k=2)
top3_acc = functools.partial(metrics.top_k_categorical_accuracy, k=3)
top4_acc = functools.partial(metrics.top_k_categorical_accuracy, k=4)
top5_acc = functools.partial(metrics.top_k_categorical_accuracy, k=5)
top2_acc.__name__ = 'top2_acc'
top3_acc.__name__ = 'top3_acc'
top4_acc.__name__ = 'top4_acc'
top5_acc.__name__ = 'top5_acc'

model.compile(loss='categorical_crossentropy',
              optimizer=optimizers.RMSprop(learning_rate=1e-4), #Decrease learning rate
              metrics=['accuracy',top2_acc, top3_acc, top4_acc, top5_acc])

# Image size and batch size
image_size = (72, 96)
batch_size = 4

class SafeImageDataGenerator(Sequence):
    def __init__(self, directory, batch_size, target_size, class_mode='categorical', shuffle=True):
        self.directory = directory
        self.batch_size = batch_size
        self.target_size = target_size
        self.class_mode = class_mode
        self.shuffle = shuffle

        self.classes = sorted(os.listdir(directory))
        self.class_indices = dict(zip(self.classes, range(len(self.classes))))

        self.filenames = []
        self.labels = []
        for class_name in self.classes:
            class_path = os.path.join(directory, class_name)
            for filename in os.listdir(class_path):
                self.filenames.append(os.path.join(class_name, filename))
                self.labels.append(self.class_indices[class_name])

        self.num_samples = len(self.filenames)
        self.on_epoch_end()

    def __len__(self):
        return int(np.ceil(self.num_samples / float(self.batch_size)))

    def __getitem__(self, idx):
        batch_filenames = self.filenames[idx * self.batch_size:(idx + 1) * self.batch_size]
        batch_labels = self.labels[idx * self.batch_size:(idx + 1) * self.batch_size]

        batch_images = []
        valid_labels = []

        for filename, label in zip(batch_filenames, batch_labels):
            try:
                img = Image.open(os.path.join(self.directory, filename)).convert('RGB')
                img = img.resize(self.target_size)
                img_array = np.array(img) / 255.0  # Normalize to [0,1]
                batch_images.append(img_array)
                valid_labels.append(label)
            except Exception as e:
                print(f"Error loading image {filename}: {str(e)}")

        if not batch_images:
            return self.__getitem__((idx + 1) % len(self))

        batch_x = np.array(batch_images)
        batch_y = np.array(valid_labels)

        if self.class_mode == 'categorical':
            batch_y = tf.keras.utils.to_categorical(batch_y, num_classes=len(self.classes))

        return batch_x, batch_y

    def on_epoch_end(self):
        if self.shuffle:
            temp = list(zip(self.filenames, self.labels))
            np.random.shuffle(temp)
            self.filenames, self.labels = zip(*temp)

train_generator = SafeImageDataGenerator(
    directory=train_dir,
    batch_size=batch_size,
    target_size=image_size,
    class_mode='categorical'
)

val_generator = SafeImageDataGenerator(
    directory=val_dir,
    batch_size=batch_size,
    target_size=image_size,
    class_mode='categorical'
)

test_generator = SafeImageDataGenerator(
    directory=test_dir,
    batch_size=batch_size,
    target_size=image_size,
    class_mode='categorical'
)

history = model.fit(
    train_generator,
    steps_per_epoch=len(train_generator),
    epochs=10,
    validation_data=val_generator,
    validation_steps=len(val_generator),
    workers=0,
    max_queue_size=0
)

test_loss, test_acc = model.evaluate(test_generator, steps=test_generator.samples // batch_size)
print(f'Test accuracy: {test_acc}')

